{
  "plan_overview": {
    "objective": "Implement critical fixes for working infinite mode system",
    "total_fixes": 7,
    "critical_fixes": 3,
    "medium_priority": 2,
    "future_todos": 2,
    "estimated_implementation_time": "2-3 hours with testing",
    "risk_assessment": "LOW - focusing on straightforward, low-risk fixes"
  },
  "success_definition": {
    "infinite_mode_working": "System processes all categories and products without interruption",
    "no_duplicate_processing": "Each product processed exactly once",
    "resumption_working": "System resumes from correct position after interruption",
    "authentication_robust": "System re-authenticates when needed",
    "performance_optimized": "No redundant 276-chunk processing"
  },
  "detailed_plan": {
    "categorization": {
      "critical_fixes": {
        "description": "Must be implemented for working infinite mode system",
        "risk_tolerance": "Low risk, straightforward implementation only",
        "fixes": {
          "fix_1_processing_state_resumption": {
            "priority": "\ud83d\udea8 CRITICAL",
            "description": "Fix hybrid processing to continue supplier scraping from correct index",
            "current_bug": "System skips remaining 120 products after restart, goes to Amazon extraction",
            "expected_behavior": "Continue scraping from product 30 where left off",
            "implementation_complexity": "LOW",
            "implementation_risk": "LOW",
            "testing_requirements": "Verify resumption from specific index",
            "blocking_issue": true
          },
          "fix_2_chunk_skip_logic": {
            "priority": "\ud83d\udea8 CRITICAL",
            "description": "Prevent 276-chunk reprocessing of same products",
            "current_bug": "Same 149 products processed 276 times before financial reports",
            "expected_behavior": "Process each product only once, skip redundant chunks",
            "implementation_complexity": "LOW",
            "implementation_risk": "LOW",
            "testing_requirements": "Verify no duplicate processing in logs",
            "blocking_issue": true
          },
          "fix_3_authentication_fallback": {
            "priority": "\ud83d\udea8 CRITICAL",
            "description": "Add authentication triggers during supplier scraping",
            "current_bug": "Authentication fallback not triggered during supplier phase",
            "expected_behavior": "Re-authenticate when price access fails during scraping",
            "implementation_complexity": "MEDIUM",
            "implementation_risk": "LOW",
            "testing_requirements": "Verify authentication trigger on logout",
            "blocking_issue": true
          }
        }
      },
      "medium_priority_fixes": {
        "description": "Important for system quality but not blocking",
        "risk_tolerance": "Medium risk acceptable",
        "fixes": {
          "fix_4_match_method_accuracy": {
            "priority": "\u26a0\ufe0f MEDIUM",
            "description": "Fix match_method labeling (EAN vs title)",
            "current_bug": "Shows 'EAN' when title matching used",
            "expected_behavior": "Accurate match method labeling",
            "implementation_complexity": "LOW",
            "implementation_risk": "LOW",
            "testing_requirements": "Verify correct method labels in linking map",
            "blocking_issue": false
          },
          "fix_5_financial_report_timing": {
            "priority": "\u26a0\ufe0f MEDIUM",
            "description": "Implement periodic financial reports per config toggle",
            "current_bug": "Reports only at end vs config setting of 3",
            "expected_behavior": "Generate reports every N products as configured",
            "implementation_complexity": "MEDIUM",
            "implementation_risk": "MEDIUM",
            "testing_requirements": "Verify periodic report generation",
            "blocking_issue": false
          }
        }
      },
      "future_todos": {
        "description": "Improvements with complexity/risk not suitable for immediate implementation",
        "risk_tolerance": "High risk, complex implementation",
        "fixes": {
          "future_1_multi_price_extraction": {
            "priority": "\ud83d\udccb FUTURE TODO",
            "description": "Extract multiple prices (regular + subscription)",
            "current_behavior": "Single price extraction",
            "proposed_behavior": "Create duplicate linking map entries for multiple prices",
            "implementation_complexity": "HIGH",
            "implementation_risk": "HIGH",
            "reason_for_deferral": "Requires significant changes to price extraction logic",
            "blocking_issue": false
          },
          "future_2_advanced_state_validation": {
            "priority": "\ud83d\udccb FUTURE TODO",
            "description": "Comprehensive state consistency validation",
            "implementation_complexity": "HIGH",
            "implementation_risk": "MEDIUM",
            "reason_for_deferral": "Complex cross-component validation logic",
            "blocking_issue": false
          }
        }
      }
    },
    "sequence": {
      "implementation_order": [
        {
          "step": 1,
          "fix_id": "fix_1_processing_state_resumption",
          "title": "\ud83d\udea8 CRITICAL: Processing State Resumption Logic",
          "implementation_steps": [
            "1.1: Identify hybrid processing resumption logic location",
            "1.2: Modify condition to check supplier scraping completion",
            "1.3: Add logic to continue from last processed index",
            "1.4: Update state validation logic"
          ],
          "testing_requirements": [
            "Test 1.1: Run system, interrupt after 29 products",
            "Test 1.2: Restart system, verify continues from product 30",
            "Test 1.3: Verify no products skipped or duplicated",
            "Test 1.4: Complete full run to verify end-to-end"
          ],
          "success_criteria": [
            "\u2705 System resumes from correct index after interruption",
            "\u2705 No products skipped between runs",
            "\u2705 Logs show 'RESUMING supplier scraping from index X'"
          ],
          "rollback_plan": "Revert to original resumption logic if issues detected"
        },
        {
          "step": 2,
          "fix_id": "fix_2_chunk_skip_logic",
          "title": "\ud83d\udea8 CRITICAL: 276-Chunk Skip Logic",
          "implementation_steps": [
            "2.1: Add chunk processing skip condition",
            "2.2: Implement already-processed product detection",
            "2.3: Skip redundant chunk processing when appropriate",
            "2.4: Ensure financial reports still generate"
          ],
          "testing_requirements": [
            "Test 2.1: Verify chunks not reprocessed when products exist",
            "Test 2.2: Verify financial reports generate correctly",
            "Test 2.3: Check logs show 'Skipping chunk - already processed'",
            "Test 2.4: Performance test - no 276x redundant processing"
          ],
          "success_criteria": [
            "\u2705 No redundant chunk processing in logs",
            "\u2705 Products processed only once",
            "\u2705 Financial reports generate at appropriate time",
            "\u2705 Significant performance improvement"
          ],
          "rollback_plan": "Disable skip logic if financial reports affected"
        },
        {
          "step": 3,
          "fix_id": "fix_3_authentication_fallback",
          "title": "\ud83d\udea8 CRITICAL: Authentication Fallback Integration",
          "implementation_steps": [
            "3.1: Add authentication check before each category",
            "3.2: Integrate price missing counter during supplier scraping",
            "3.3: Trigger re-authentication when thresholds reached",
            "3.4: Verify authentication status logging"
          ],
          "testing_requirements": [
            "Test 3.1: Manually logout during supplier scraping",
            "Test 3.2: Verify system detects price access failure",
            "Test 3.3: Verify authentication fallback triggers",
            "Test 3.4: Verify successful re-authentication"
          ],
          "success_criteria": [
            "\u2705 Authentication checked before each category",
            "\u2705 Re-authentication triggered on price failures",
            "\u2705 System continues processing after re-auth",
            "\u2705 Logs show authentication trigger events"
          ],
          "rollback_plan": "Disable authentication checks if system becomes unstable"
        },
        {
          "step": 4,
          "fix_id": "fix_4_match_method_accuracy",
          "title": "\u26a0\ufe0f MEDIUM: Match Method Labeling Accuracy",
          "implementation_steps": [
            "4.1: Locate match method assignment logic",
            "4.2: Track actual search method used",
            "4.3: Update linking map with correct method",
            "4.4: Verify labeling accuracy"
          ],
          "testing_requirements": [
            "Test 4.1: Force EAN search failure to trigger title search",
            "Test 4.2: Verify linking map shows 'title' method",
            "Test 4.3: Verify EAN searches show 'EAN' method",
            "Test 4.4: Check random sample for accuracy"
          ],
          "success_criteria": [
            "\u2705 Match method accurately reflects search used",
            "\u2705 Title searches labeled as 'title'",
            "\u2705 EAN searches labeled as 'EAN'",
            "\u2705 Linking map entries consistent"
          ],
          "rollback_plan": "Revert to previous labeling if issues detected"
        }
      ],
      "testing_standards_compliance": {
        "reference": "CLAUDE.MD sections: CRITICAL TESTING & VERIFICATION STANDARDS, UPDATE PROTOCOL",
        "mandatory_verification": [
          "\ud83d\udea8 MANDATORY_FIX_TESTING: Thoroughly test each fix",
          "\ud83d\udea8 NO_CLAIMS_WITHOUT_VERIFICATION: Verify actual functionality",
          "\ud83d\udea8 MANDATORY_FILE_VERIFICATION_PROTOCOL: Check files exist with correct content",
          "\u26a0\ufe0f UPDATE_PROTOCOL_COMPLIANCE: Cascading updates for any changes"
        ],
        "success_validation": [
          "\u2705 ZERO ERRORS: No errors in execution logs",
          "\u2705 END-TO-END COMPLETION: Complete functional pipeline working",
          "\u2705 ACTUAL_SYSTEM_TESTING: Use actual system, never test versions"
        ]
      }
    },
    "templates": {
      "fix_1_processing_state_resumption": {
        "location": "tools/passive_extraction_workflow_latest.py - hybrid processing logic",
        "template": "\n# \ud83d\udea8 CRITICAL FIX: Processing State Resumption Logic\ndef _should_continue_supplier_scraping(self):\n    \"\"\"Check if supplier scraping should continue from last index\"\"\"\n    if not hasattr(self, 'state_manager') or not self.state_manager:\n        return True\n    \n    state = self.state_manager.get_processing_state()\n    last_index = state.get('last_processed_index', 0)\n    \n    # Load cached products to check total count\n    cache_path = self._get_supplier_cache_path()\n    if os.path.exists(cache_path):\n        with open(cache_path, 'r') as f:\n            cached_products = json.load(f)\n        \n        total_products = len(cached_products)\n        if last_index < total_products:\n            self.log.info(f\"\ud83d\udd04 SUPPLIER SCRAPING INCOMPLETE: {last_index}/{total_products} - continuing from index {last_index}\")\n            return True\n        else:\n            self.log.info(f\"\u2705 SUPPLIER SCRAPING COMPLETE: {last_index}/{total_products} - proceeding to Amazon extraction\")\n            return False\n    \n    return True\n\n# MODIFY existing hybrid processing logic:\ndef _run_hybrid_processing_mode(self, ...):\n    # BEFORE chunk processing, check if supplier scraping should continue\n    if self._should_continue_supplier_scraping():\n        # Continue supplier scraping from last index\n        self._continue_supplier_scraping_from_index()\n    else:\n        # Proceed to Amazon extraction phase\n        self._proceed_to_amazon_extraction()\n",
        "testing_code": "\n# Test case for processing state resumption\ndef test_processing_state_resumption():\n    # 1. Start system, let it process 29 products\n    # 2. Interrupt system  \n    # 3. Restart system\n    # 4. Verify continues from product 30\n    # 5. Verify no products skipped\n    pass\n"
      },
      "fix_2_chunk_skip_logic": {
        "location": "tools/passive_extraction_workflow_latest.py - chunk processing loop",
        "template": "\n# \ud83d\udea8 CRITICAL FIX: 276-Chunk Skip Logic\ndef _should_skip_chunk_processing(self):\n    \"\"\"Check if chunk processing should be skipped due to already processed products\"\"\"\n    # Check if we have extracted products\n    cache_path = self._get_supplier_cache_path()\n    if not os.path.exists(cache_path):\n        return False\n    \n    # Check if we have processed products through Amazon\n    linking_map = self._load_linking_map(self.supplier_name)\n    if not linking_map:\n        return False\n    \n    # Check if financial reports already exist\n    financial_reports_dir = self._get_financial_reports_dir()\n    if financial_reports_dir.exists():\n        report_files = list(financial_reports_dir.glob(\"fba_financial_report_*.csv\"))\n        if report_files:\n            latest_report = max(report_files, key=lambda x: x.stat().st_mtime)\n            # Check if report is recent (within last hour)\n            import time\n            if (time.time() - latest_report.stat().st_mtime) < 3600:\n                self.log.info(f\"\u2705 RECENT FINANCIAL REPORT EXISTS: {latest_report.name} - skipping chunk reprocessing\")\n                return True\n    \n    return False\n\n# MODIFY chunk processing loop:\nfor chunk_start in range(0, len(category_urls_to_scrape), chunk_size):\n    if self._should_skip_chunk_processing():\n        self.log.info(f\"\u23ed\ufe0f SKIPPING CHUNK {chunk_start//chunk_size + 1}: Products already processed\")\n        continue\n    \n    # Continue with normal chunk processing...\n",
        "testing_code": "\n# Test case for chunk skip logic\ndef test_chunk_skip_logic():\n    # 1. Run system to completion\n    # 2. Restart system immediately  \n    # 3. Verify chunks are skipped\n    # 4. Verify financial reports not regenerated\n    # 5. Check logs for \"SKIPPING CHUNK\" messages\n    pass\n"
      },
      "fix_3_authentication_fallback": {
        "location": "tools/passive_extraction_workflow_latest.py - supplier scraping loop",
        "template": "\n# \ud83d\udea8 CRITICAL FIX: Authentication Fallback Integration\nasync def _check_authentication_before_category(self, category_url):\n    \"\"\"Check authentication before processing each category\"\"\"\n    if hasattr(self, 'auth_service') and self.auth_service:\n        try:\n            # Check if session is still authenticated\n            page = await self.browser_manager.get_page()\n            is_authenticated = await self.auth_service._is_session_authenticated(page)\n            \n            if not is_authenticated:\n                self.log.warning(\"\ud83d\udd10 AUTHENTICATION LOST: Re-authenticating before category processing\")\n                credentials = self._get_credentials()\n                success, method = await self.auth_service.ensure_authenticated_session(page, credentials, force_reauth=True)\n                \n                if success:\n                    self.log.info(f\"\u2705 RE-AUTHENTICATION SUCCESSFUL: {method}\")\n                else:\n                    self.log.error(\"\u274c RE-AUTHENTICATION FAILED: Cannot continue\")\n                    return False\n            \n            return True\n        except Exception as e:\n            self.log.error(f\"Authentication check error: {e}\")\n            return True  # Continue on error to avoid blocking\n    \n    return True\n\n# MODIFY supplier scraping loop:\nfor category_url in category_urls:\n    # Check authentication before each category\n    if not await self._check_authentication_before_category(category_url):\n        break\n    \n    # Continue with category processing...\n",
        "testing_code": "\n# Test case for authentication fallback\ndef test_authentication_fallback():\n    # 1. Start system\n    # 2. Manually logout during supplier scraping\n    # 3. Verify system detects logout\n    # 4. Verify re-authentication occurs\n    # 5. Verify processing continues\n    pass\n"
      }
    }
  },
  "next_steps": [
    "1. Start with Fix 1: Processing State Resumption Logic",
    "2. Test thoroughly before proceeding to next fix",
    "3. Implement fixes in sequence with testing checkpoints",
    "4. Follow CLAUDE.MD testing standards for each fix",
    "5. Verify infinite mode operation at completion"
  ]
}