#!/usr/bin/env python3
"""
Poundwholesale Co Uk Product Extractor Script
Auto-generated by IntelligentSupplierScriptGenerator on 2025-07-08T18:38:37.171528

Provides product extraction for https://www.poundwholesale.co.uk/
"""

import asyncio
import logging
import json
from datetime import datetime
from typing import List, Dict, Any
from playwright.async_api import async_playwright, Page

# Configure logging
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
log = logging.getLogger(__name__)

# Configuration from discovery
SUPPLIER_URL = "https://www.poundwholesale.co.uk/"
CONTAINER_SELECTOR = ".product-item"
TITLE_SELECTOR = "h2, h3, .title"
PRICE_SELECTOR = ".price"
URL_SELECTOR = "a"
IMAGE_SELECTOR = "img"

class Poundwholesale_Co_UkProductExtractor:
    """Product extraction for https://www.poundwholesale.co.uk/"""
    
    def __init__(self, max_pages: int = 2, test_mode: bool = False):
        self.max_pages = max_pages
        self.test_mode = test_mode
        self.page: Page = None
        self.browser = None
        self.context = None
    
    async def connect_to_browser(self) -> bool:
        """Connect to existing Chrome debug instance"""
        try:
            playwright = await async_playwright().start()
            self.browser = await playwright.chromium.connect_over_cdp("http://localhost:9222")
            
            if self.browser.contexts:
                self.context = self.browser.contexts[0]
            else:
                self.context = await self.browser.new_context()
            
            if self.context.pages:
                self.page = self.context.pages[0]
            else:
                self.page = await self.context.new_page()
                
            await self.page.bring_to_front()
            return True
            
        except Exception as e:
            log.error(f"Failed to connect to browser: {e}")
            return False
    
    async def extract_products(self, start_url: str = None) -> List[Dict[str, Any]]:
        """Extract products from supplier website"""
        try:
            log.info(f"🛍️ Starting product extraction for {self.max_pages} pages")
            
            base_url = start_url or SUPPLIER_URL
            products = []
            
            for page_num in range(1, self.max_pages + 1):
                log.info(f"📄 Processing page {page_num}")
                
                # Navigate to page
                page_url = base_url if page_num == 1 else f"{base_url}?page={page_num}"
                await self.page.goto(page_url)
                await self.page.wait_for_load_state('domcontentloaded')
                
                # Extract products from current page
                page_products = await self._extract_page_products()
                products.extend(page_products)
                
                log.info(f"✅ Extracted {len(page_products)} products from page {page_num}")
                
                if self.test_mode and len(products) >= 5:
                    log.info("🧪 Test mode: stopping after 5 products")
                    break
            
            log.info(f"✅ Product extraction completed: {len(products)} total products")
            return products
            
        except Exception as e:
            log.error(f"Product extraction failed: {e}")
            return []
    
    async def _extract_page_products(self) -> List[Dict[str, Any]]:
        """Extract products from current page"""
        try:
            # Find product containers
            containers = await self.page.query_selector_all(CONTAINER_SELECTOR)
            log.info(f"🔍 Found {len(containers)} product containers")
            
            products = []
            for i, container in enumerate(containers):
                try:
                    product = await self._extract_single_product(container)
                    if product:
                        products.append(product)
                except Exception as e:
                    log.warning(f"Failed to extract product {i}: {e}")
                    continue
            
            return products
            
        except Exception as e:
            log.error(f"Page extraction failed: {e}")
            return []
    
    async def _extract_single_product(self, container) -> Dict[str, Any]:
        """Extract data from a single product container"""
        try:
            product = {
                "extraction_timestamp": datetime.now().isoformat(),
                "source_url": self.page.url
            }
            
            # Extract title
            try:
                title_element = await container.query_selector(TITLE_SELECTOR)
                if title_element:
                    product["title"] = (await title_element.text_content()).strip()
            except:
                pass
            
            # Extract price
            try:
                price_element = await container.query_selector(PRICE_SELECTOR)
                if price_element:
                    price_text = (await price_element.text_content()).strip()
                    product["price"] = price_text
            except:
                pass
            
            # Extract URL
            try:
                url_element = await container.query_selector(URL_SELECTOR)
                if url_element:
                    href = await url_element.get_attribute("href")
                    if href:
                        # Make absolute URL
                        if href.startswith("/"):
                            href = f"{self.supplier_url.rstrip('/')}{href}"
                        product["url"] = href
            except:
                pass
            
            # Extract image
            try:
                img_element = await container.query_selector(IMAGE_SELECTOR)
                if img_element:
                    src = await img_element.get_attribute("src")
                    if src:
                        product["image_url"] = src
            except:
                pass
            
            # Only return product if we got at least title or URL
            if product.get("title") or product.get("url"):
                return product
            return None
            
        except Exception as e:
            log.error(f"Single product extraction failed: {e}")
            return None

# Test function for validation
async def test_extraction(max_pages: int = 2) -> Dict[str, Any]:
    """Test product extraction functionality"""
    try:
        extractor = Poundwholesale_Co_UkProductExtractor(max_pages=max_pages, test_mode=True)
        
        if not await extractor.connect_to_browser():
            return {"success": False, "error": "Failed to connect to browser"}
        
        products = await extractor.extract_products()
        
        return {
            "success": True,
            "products_extracted": len(products),
            "sample_products": products[:3] if products else [],
            "total_products": len(products)
        }
        
    except Exception as e:
        return {"success": False, "error": str(e)}

if __name__ == "__main__":
    # Test mode execution
    result = asyncio.run(test_extraction())
    print(json.dumps(result, indent=2))
